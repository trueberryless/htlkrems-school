{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec829dc2",
   "metadata": {},
   "source": [
    "# 3.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc304814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is introduction to nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is likely to be useful, to people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning is the new electrcity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there would be less hype around ai and more ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python is the best tool!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r is good langauage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i like this book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i want more books like this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets\n",
       "0                        this is introduction to nlp\n",
       "1              it is likely to be useful, to people \n",
       "2             machine learning is the new electrcity\n",
       "3  there would be less hype around ai and more ac...\n",
       "4                           python is the best tool!\n",
       "5                                r is good langauage\n",
       "6                                   i like this book\n",
       "7                        i want more books like this"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = [\n",
    "    'This is introduction to NLP',\n",
    "    'It is likely to be useful, to people ',\n",
    "    'Machine learning is the new electrcity',\n",
    "    'There would be less hype around AI and more action going forward',\n",
    "    'python is the best tool!','R is good langauage',\n",
    "    'I like this book','I want more books like this'\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'tweets': [col.lower() for col in tweets]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955b0c4",
   "metadata": {},
   "source": [
    "# 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5b3317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is introduction to nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is likely to be useful to people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning is the new electrcity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there would be less hype around ai and more ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python is the best tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r is good langauage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i like this book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i want more books like this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets\n",
       "0                        this is introduction to nlp\n",
       "1               it is likely to be useful to people \n",
       "2             machine learning is the new electrcity\n",
       "3  there would be less hype around ai and more ac...\n",
       "4                            python is the best tool\n",
       "5                                r is good langauage\n",
       "6                                   i like this book\n",
       "7                        i want more books like this"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "df.tweets = [re.sub(\"[^a-z0-9 .]\", '', col) for col in df.tweets]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b08841",
   "metadata": {},
   "source": [
    "# 3.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3274dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'the', 'first', 'sentence.', 'This', 'is', 'the', 'second', 'one.']\n",
      "['This', 'is', 'the', 'first', 'sentence', '.', 'This', 'is', 'the', 'second', 'one', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\trueb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "text = \"This is the first sentence. This is the second one.\"\n",
    "list_of_words = text.split()\n",
    "print(list_of_words)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "text=\"This is the first sentence. This is the second one.\"\n",
    "print(word_tokenize(text)) \n",
    "\n",
    "# As you can see, NLTK slits the punctiations into it's own element of the list whereas slit just slits whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da8ac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is introduction to NLP.', 'It is likely to be useful, to people.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text=\"This is introduction to NLP. It is likely to be useful, to people.\"\n",
    "print(sent_tokenize(text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d90bec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', \"'\", 're', 'moving', 'to', 'N', '.', 'Y', '.!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "text=\"We're moving to N.Y.!\"\n",
    "Tokenizer=WordPunctTokenizer()\n",
    "print(Tokenizer.tokenize(text)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f689a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 're', 'moving', 'to', 'N', 'Y']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "text=\"We're moving to N.Y.!\"\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "print(tokenizer.tokenize(text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34837e1d",
   "metadata": {},
   "source": [
    "# 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c938861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is introduction to nlp</td>\n",
       "      <td>[this, is, introduction, to, nlp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is likely to be useful to people</td>\n",
       "      <td>[it, is, likely, to, be, useful, to, people]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning is the new electrcity</td>\n",
       "      <td>[machine, learning, is, the, new, electrcity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there would be less hype around ai and more ac...</td>\n",
       "      <td>[there, would, be, less, hype, around, ai, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python is the best tool</td>\n",
       "      <td>[python, is, the, best, tool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r is good langauage</td>\n",
       "      <td>[r, is, good, langauage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i like this book</td>\n",
       "      <td>[i, like, this, book]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i want more books like this</td>\n",
       "      <td>[i, want, more, books, like, this]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  \\\n",
       "0                        this is introduction to nlp   \n",
       "1               it is likely to be useful to people    \n",
       "2             machine learning is the new electrcity   \n",
       "3  there would be less hype around ai and more ac...   \n",
       "4                            python is the best tool   \n",
       "5                                r is good langauage   \n",
       "6                                   i like this book   \n",
       "7                        i want more books like this   \n",
       "\n",
       "                                           tokenized  \n",
       "0                  [this, is, introduction, to, nlp]  \n",
       "1       [it, is, likely, to, be, useful, to, people]  \n",
       "2      [machine, learning, is, the, new, electrcity]  \n",
       "3  [there, would, be, less, hype, around, ai, and...  \n",
       "4                      [python, is, the, best, tool]  \n",
       "5                           [r, is, good, langauage]  \n",
       "6                              [i, like, this, book]  \n",
       "7                 [i, want, more, books, like, this]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized'] = [tokenizer.tokenize(col) for col in df['tweets']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238c80a",
   "metadata": {},
   "source": [
    "# 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553012e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373\n",
      "549\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "with open('dataScientistJobDesc.txt', 'r', encoding=\"UTF-8\") as file:\n",
    "    data= file.read()\n",
    "    data_list = word_tokenize(data)\n",
    "    print(len(data_list))\n",
    "    data_set = set(data_list)\n",
    "    print(len(data_set))\n",
    "    nltk_tokens = data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99e436",
   "metadata": {},
   "source": [
    "# 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0601797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple erwägt den Kauf eines österreichischen Startups um 6 Mio. Euro.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "doc = nlp(\"Apple erwägt den Kauf eines österreichischen Startups um 6 Mio. Euro.\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6634aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple                <class 'spacy.tokens.token.Token'>\n",
      "erwägt               <class 'spacy.tokens.token.Token'>\n",
      "den                  <class 'spacy.tokens.token.Token'>\n",
      "Kauf                 <class 'spacy.tokens.token.Token'>\n",
      "eines                <class 'spacy.tokens.token.Token'>\n",
      "österreichischen     <class 'spacy.tokens.token.Token'>\n",
      "Startups             <class 'spacy.tokens.token.Token'>\n",
      "um                   <class 'spacy.tokens.token.Token'>\n",
      "6                    <class 'spacy.tokens.token.Token'>\n",
      "Mio.                 <class 'spacy.tokens.token.Token'>\n",
      "Euro                 <class 'spacy.tokens.token.Token'>\n",
      ".                    <class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text:{20}}\",type(token)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75fd4836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1454\n",
      "561\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "with open('dataScientistJobDesc.txt', 'r', encoding=\"UTF-8\") as file:\n",
    "    data = file.read()\n",
    "    data_list = nlp(data)\n",
    "    print(len(data_list))\n",
    "    data_set = set([token.text for token in data_list])\n",
    "    print(len(data_set))\n",
    "    spacy_tokens = data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958f42d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Director/VP/SVP',\n",
       " 'Hands-on',\n",
       " 'Problem-solving',\n",
       " 'd3.js.',\n",
       " 'data-driven',\n",
       " 'don',\n",
       " 'entry-level',\n",
       " 'industries/sectors',\n",
       " 'isn',\n",
       " 'k-Nearest',\n",
       " 'll',\n",
       " 'must-have',\n",
       " 'non-technical',\n",
       " 'problem-solving',\n",
       " 're',\n",
       " 's',\n",
       " 'senior-level',\n",
       " 't'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy behandelt offensichtlich gewisse Zeichenketten (besonders Sonderzeichen) anders.\n",
    "# Beispielsweise sieht man unten, dass Kommas, Punkte und Schrägstriche nicht gleich tokenized werden.\n",
    "nltk_tokens.difference(spacy_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c4663",
   "metadata": {},
   "source": [
    "# 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "862704ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trueb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['How', 'develop', 'chatbot', 'Python']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "text = \"How to develop a chatbot in Python\"\n",
    "result = [word for word in text.split() if word not in stop]\n",
    "result \n",
    "\n",
    "# Da How nicht in den Stopwords vorkommt, wurde es nicht aus dem Satz / der Liste entfernt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38662ab",
   "metadata": {},
   "source": [
    "# 3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a777e93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>introduction nlp</td>\n",
       "      <td>[introduction, nlp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>likely useful people</td>\n",
       "      <td>[likely, useful, people]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning new electrcity</td>\n",
       "      <td>[machine, learning, new, electrcity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would less hype around ai action going forward</td>\n",
       "      <td>[would, less, hype, around, ai, action, going,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python best tool</td>\n",
       "      <td>[python, best, tool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r good langauage</td>\n",
       "      <td>[r, good, langauage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>like book</td>\n",
       "      <td>[like, book]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>want books like</td>\n",
       "      <td>[want, books, like]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweets  \\\n",
       "0                                introduction nlp   \n",
       "1                            likely useful people   \n",
       "2                 machine learning new electrcity   \n",
       "3  would less hype around ai action going forward   \n",
       "4                                python best tool   \n",
       "5                                r good langauage   \n",
       "6                                       like book   \n",
       "7                                 want books like   \n",
       "\n",
       "                                           tokenized  \n",
       "0                                [introduction, nlp]  \n",
       "1                           [likely, useful, people]  \n",
       "2               [machine, learning, new, electrcity]  \n",
       "3  [would, less, hype, around, ai, action, going,...  \n",
       "4                               [python, best, tool]  \n",
       "5                               [r, good, langauage]  \n",
       "6                                       [like, book]  \n",
       "7                                [want, books, like]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords_and_join(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(remove_stopwords_and_join)\n",
    "df['tokenized'] = [tokenizer.tokenize(col) for col in df['tweets']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22613383",
   "metadata": {},
   "source": [
    "# 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611f6ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'runner', 'run', 'ran', 'run']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pt = PorterStemmer()\n",
    "words = ['run','runner','running','ran','runs']\n",
    "[pt.stem(word) for word in words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfdefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=['I like fishing','I eat fish','There are many fishes in pound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f8c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaed8d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i like fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i eat fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there are many fishes in pound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "0                     i like fish\n",
       "1                      i eat fish\n",
       "2  there are many fishes in pound"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([pt.stem(word) for word in text])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5e4b2",
   "metadata": {},
   "source": [
    "# 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "078fc001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\trueb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\trueb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks: rock\n",
      "studies: study\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(\"rocks:\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"studies:\", lemmatizer.lemmatize(\"studies\"))\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37612d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I eat fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are many fishes in pound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "0                  I like fishing\n",
       "1                      I eat fish\n",
       "2  There are many fishes in pound"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([lemmatizer.lemmatize(word) for word in text])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
